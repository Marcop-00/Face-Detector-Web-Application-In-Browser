<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' 'unsafe-eval' https://cdn.tailwindcss.com https://cdn.jsdelivr.net; style-src 'self' 'unsafe-inline' https://fonts.googleapis.com; font-src https://fonts.gstatic.com; connect-src 'self' https://cdn.jsdelivr.net https://storage.googleapis.com; img-src 'self' blob: data:; media-src 'self' blob:;">
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>FaceDetect Pro | Client-Side ML</title>

    <script src="https://cdn.tailwindcss.com"></script>

    <link
      rel="stylesheet"
      href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0"
    />

    <style>
      /* Glassmorphism Utilities */
      .glass {
        background: rgba(255, 255, 255, 0.05);
        backdrop-filter: blur(10px);
        -webkit-backdrop-filter: blur(10px);
        border: 1px solid rgba(255, 255, 255, 0.1);
      }

      /* Canvas Overlay Alignment */
      .video-container {
        position: relative;
        width: 100%;
        max-width: 800px; /* Limits max video width */
        border-radius: 1rem;
        overflow: hidden;
        box-shadow:
          0 20px 25px -5px rgba(0, 0, 0, 0.5),
          0 10px 10px -5px rgba(0, 0, 0, 0.4);
      }

      video {
        display: block;
        width: 100%;
        height: auto;
        transform: scaleX(-1); /* Mirror effect */
      }

      canvas.output_canvas {
        position: absolute;
        left: 0;
        top: 0;
        width: 100%;
        height: 100%;
        pointer-events: none; /* Let clicks pass through */
        transform: scaleX(-1); /* Mirror effect to match video */
      }

      /* Smooth loading spinner */
      .loader {
        border: 3px solid rgba(255, 255, 255, 0.1);
        border-radius: 50%;
        border-top: 3px solid #3b82f6;
        width: 24px;
        height: 24px;
        animation: spin 1s linear infinite;
        display: none;
      }

      @keyframes spin {
        0% {
          transform: rotate(0deg);
        }
        100% {
          transform: rotate(360deg);
        }
      }
    </style>
  </head>
  <body
    class="bg-gray-900 text-gray-100 min-h-screen flex flex-col items-center justify-center p-4 font-sans selection:bg-blue-500 selection:text-white"
  >
    <header class="text-center mb-6">
      <h1
        class="text-3xl font-bold bg-clip-text text-transparent bg-gradient-to-r from-blue-400 to-emerald-400"
      >
        FaceDetect Pro
      </h1>
      <p
        class="text-gray-400 text-sm mt-2 flex items-center justify-center gap-2"
      >
        <span class="material-symbols-outlined text-emerald-400 text-lg"
          >lock</span
        >
        All processing is local; no image data leaves this device.
      </p>
    </header>

    <main class="w-full flex flex-col items-center gap-6">
      <div class="video-container bg-black relative aspect-video" id="liveView">
        <div
          id="placeholder"
          class="absolute inset-0 flex flex-col items-center justify-center text-gray-500 z-10"
        >
          <span class="material-symbols-outlined text-6xl mb-2">face</span>
          <p>Camera is offline</p>
        </div>

        <video id="webcam" autoplay playsinline></video>
        <canvas class="output_canvas" id="output_canvas"></canvas>

        <div
          id="hud"
          class="absolute top-4 left-4 glass px-3 py-2 rounded-lg text-xs font-mono text-emerald-300 hidden z-20"
        >
          <div class="flex flex-col gap-1">
            <span id="fpsDisplay">Latency: -- ms</span>
            <span id="faceCountDisplay">Faces: 0</span>
          </div>
        </div>
      </div>

      <div
        class="flex flex-wrap gap-4 justify-center items-center w-full max-w-lg"
      >
        <button
          id="webcamButton"
          class="group relative px-6 py-3 rounded-full bg-blue-600 hover:bg-blue-500 transition-all duration-200 disabled:opacity-50 disabled:cursor-not-allowed flex items-center gap-2 font-semibold shadow-lg shadow-blue-900/50"
        >
          <span class="loader" id="btnLoader"></span>
          <span
            class="material-symbols-outlined group-hover:scale-110 transition-transform"
            >videocam</span
          >
          <span id="webcamButtonText">Enable Camera</span>
        </button>

        <button
          id="snapshotBtn"
          disabled
          class="px-6 py-3 rounded-full glass hover:bg-white/10 transition-all duration-200 disabled:opacity-30 disabled:cursor-not-allowed flex items-center gap-2 font-semibold text-gray-200"
        >
          <span class="material-symbols-outlined">photo_camera</span>
          <span>Snapshot</span>
        </button>
      </div>

      <div
        id="errorMsg"
        class="hidden fixed bottom-5 bg-red-900/90 border border-red-500 text-red-100 px-6 py-3 rounded-lg shadow-xl backdrop-blur-sm z-50"
      >
        Error message here
      </div>
    </main>

    <script type="module">
      import {
        FaceDetector,
        FilesetResolver,
      } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0";

      // DOM Elements
      const video = document.getElementById("webcam");
      const canvasElement = document.getElementById("output_canvas");
      const canvasCtx = canvasElement.getContext("2d");
      const webcamBtn = document.getElementById("webcamButton");
      const webcamBtnText = document.getElementById("webcamButtonText");
      const btnLoader = document.getElementById("btnLoader");
      const snapshotBtn = document.getElementById("snapshotBtn");
      const hud = document.getElementById("hud");
      const fpsDisplay = document.getElementById("fpsDisplay");
      const countDisplay = document.getElementById("faceCountDisplay");
      const placeholder = document.getElementById("placeholder");
      const errorMsg = document.getElementById("errorMsg");

      let faceDetector;
      let runningMode = "VIDEO";
      let lastVideoTime = -1;
      let isCamRunning = false;
      let animationId;

      // --- 1. Initialization ---

      async function initializeFaceDetector() {
        try {
          // Load WASM assets
          const vision = await FilesetResolver.forVisionTasks(
            "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm",
          );

          // Configure Detector
          faceDetector = await FaceDetector.createFromOptions(vision, {
            baseOptions: {
              modelAssetPath:
                "https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite",
              delegate: "GPU", // Attempt to use GPU
            },
            runningMode: runningMode,
            minDetectionConfidence: 0.5,
            minSuppressionThreshold: 0.3,
          });

          // UI Ready State
          webcamBtn.disabled = false;
          webcamBtnText.innerText = "Start Camera";
          btnLoader.style.display = "none";
        } catch (error) {
          showError(
            "Failed to load AI Model. Browser might not support WASM/WebGL.",
          );
          console.error(error);
        }
      }

      // Start initialization immediately
      webcamBtn.disabled = true;
      webcamBtnText.innerText = "Loading Model...";
      btnLoader.style.display = "block";
      initializeFaceDetector();

      // --- 2. Webcam Logic ---

      webcamBtn.addEventListener("click", toggleCamera);

      function toggleCamera() {
        if (!faceDetector) {
          showError("Face Detector not loaded yet.");
          return;
        }

        if (isCamRunning) {
          stopCamera();
        } else {
          startCamera();
        }
      }

      async function startCamera() {
        try {
          const constraints = {
            video: {
              width: { ideal: 1280 },
              height: { ideal: 720 },
              facingMode: "user",
            },
          };

          const stream = await navigator.mediaDevices.getUserMedia(constraints);
          video.srcObject = stream;

          video.addEventListener("loadeddata", predictWebcam);

          isCamRunning = true;
          webcamBtnText.innerText = "Stop Camera";
          webcamBtn.classList.replace("bg-blue-600", "bg-red-600");
          webcamBtn.classList.replace("hover:bg-blue-500", "hover:bg-red-500");

          placeholder.style.display = "none";
          hud.classList.remove("hidden");
          snapshotBtn.disabled = false;
        } catch (err) {
          if (err.name === "NotAllowedError") {
            showError("Camera access denied. Please allow permissions.");
          } else if (err.name === "NotFoundError") {
            showError("No camera found on this device.");
          } else {
            showError("Error accessing camera: " + err.message);
          }
        }
      }

      function stopCamera() {
        isCamRunning = false;
        cancelAnimationFrame(animationId);

        const stream = video.srcObject;
        if (stream) {
          const tracks = stream.getTracks();
          tracks.forEach((track) => track.stop());
        }
        video.srcObject = null;

        // UI Reset
        webcamBtnText.innerText = "Start Camera";
        webcamBtn.classList.replace("bg-red-600", "bg-blue-600");
        webcamBtn.classList.replace("hover:bg-red-500", "hover:bg-blue-500");
        placeholder.style.display = "flex";
        hud.classList.add("hidden");
        snapshotBtn.disabled = true;

        // Clear Canvas
        canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
      }

      // --- 3. Detection Loop ---

      async function predictWebcam() {
        // Resize logic: Ensure canvas matches video display size
        // This handles window resizing dynamically
        const displayWidth = video.clientWidth;
        const displayHeight = video.clientHeight;

        if (
          canvasElement.width !== displayWidth ||
          canvasElement.height !== displayHeight
        ) {
          canvasElement.width = displayWidth;
          canvasElement.height = displayHeight;
        }

        let startTimeMs = performance.now();

        // Run detection
        if (video.currentTime !== lastVideoTime) {
          lastVideoTime = video.currentTime;

          const detections = faceDetector.detectForVideo(
            video,
            startTimeMs,
          ).detections;

          const latency = Math.round(performance.now() - startTimeMs);
          updateHUD(latency, detections.length);

          drawResults(detections);
        }

        if (isCamRunning) {
          animationId = requestAnimationFrame(predictWebcam);
        }
      }

      // --- 4. Drawing & Overlay ---

      function drawResults(detections) {
        canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);

        const videoWidth = video.videoWidth;
        const videoHeight = video.videoHeight;
        const canvasWidth = canvasElement.width;
        const canvasHeight = canvasElement.height;

        // Ratios to map video coordinates to displayed canvas coordinates
        const scaleX = canvasWidth / videoWidth;
        const scaleY = canvasHeight / videoHeight;

        detections.forEach((detection) => {
          const box = detection.boundingBox;

          // Scale coordinates
          const x = box.originX * scaleX;
          const y = box.originY * scaleY;
          const w = box.width * scaleX;
          const h = box.height * scaleY;

          // Draw Bounding Box
          canvasCtx.strokeStyle = "#34d399"; // Emerald 400
          canvasCtx.lineWidth = 3;
          canvasCtx.beginPath();
          canvasCtx.roundRect(x, y, w, h, 8);
          canvasCtx.stroke();

          // Draw Keypoints (6 points: eyes, nose, mouth, ears)
          canvasCtx.fillStyle = "#60a5fa"; // Blue 400
          detection.keypoints.forEach((keypoint) => {
            const kx = keypoint.x * videoWidth * scaleX;
            const ky = keypoint.y * videoHeight * scaleY;

            canvasCtx.beginPath();
            canvasCtx.arc(kx, ky, 4, 0, 2 * Math.PI);
            canvasCtx.fill();
          });

          // Draw Confidence Label
          const confidence = Math.round(detection.categories[0].score * 100);
          canvasCtx.font = "14px monospace";
          canvasCtx.fillStyle = "#34d399";
          canvasCtx.fillText(`${confidence}%`, x, y - 10);
        });
      }

      function updateHUD(latency, count) {
        fpsDisplay.innerText = `Latency: ${latency}ms`;
        countDisplay.innerText = `Faces: ${count}`;

        // Color coding latency
        fpsDisplay.style.color = latency > 50 ? "#f87171" : "#6ee7b7"; // Red if slow, Green if fast
      }

      // --- 5. Snapshot Tool ---

      snapshotBtn.addEventListener("click", takeSnapshot);

      function takeSnapshot() {
        // Create an offscreen canvas to merge video and overlay
        const offScreenCanvas = document.createElement("canvas");
        offScreenCanvas.width = video.videoWidth;
        offScreenCanvas.height = video.videoHeight;
        const ctx = offScreenCanvas.getContext("2d");

        // 1. Draw Video Frame (Mirrored to match UI)
        ctx.translate(offScreenCanvas.width, 0);
        ctx.scale(-1, 1);
        ctx.drawImage(
          video,
          0,
          0,
          offScreenCanvas.width,
          offScreenCanvas.height,
        );

        // Reset transform for overlay drawing
        ctx.setTransform(1, 0, 0, 1, 0, 0);

        // 2. Draw Overlays (Re-run detection logic or scale existing canvas)
        // For highest quality, we redraw based on current canvas state but scaled up to native resolution
        // Since the output_canvas is already mirrored in CSS, but the drawing logic isn't,
        // we need to be careful. The simplest approach for "What You See Is What You Get"
        // is to draw the output_canvas onto the offscreen canvas, flipping it horizontally.

        ctx.translate(offScreenCanvas.width, 0);
        ctx.scale(-1, 1);
        ctx.drawImage(
          canvasElement,
          0,
          0,
          offScreenCanvas.width,
          offScreenCanvas.height,
        );

        // 3. Download
        const link = document.createElement("a");
        link.download = `face-detect-snap-${Date.now()}.png`;
        link.href = offScreenCanvas.toDataURL("image/png");
        link.click();
      }

      // --- 6. Utilities ---

      function showError(msg) {
        errorMsg.innerText = msg;
        errorMsg.classList.remove("hidden");
        setTimeout(() => {
          errorMsg.classList.add("hidden");
        }, 5000);
      }

      // Window Resize Handler
      // (The logic inside predictWebcam handles the canvas sizing per frame,
      // but we add a listener to ensure clean state on rapid resizes)
      window.addEventListener("resize", () => {
        if (isCamRunning) {
          const displayWidth = video.clientWidth;
          const displayHeight = video.clientHeight;
          canvasElement.width = displayWidth;
          canvasElement.height = displayHeight;
        }
      });
    </script>
  </body>
</html>
